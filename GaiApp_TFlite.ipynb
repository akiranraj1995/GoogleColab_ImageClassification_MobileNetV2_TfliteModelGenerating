{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6QHwoUT_p2X",
        "outputId": "52c8df05-4f77-4d6b-a36a-339e14b2c81b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.oauth2 import service_account\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Set up the service account credentials\n",
        "credentials = service_account.Credentials.from_service_account_file('/content/drive/MyDrive/Credentials.json')\n",
        "drive_service = build('drive', 'v3', credentials=credentials)\n",
        "\n",
        "# ID of the archive.zip file on Google Drive\n",
        "file_id = '1g3J3n2QsbLwepYzGPVZfyOyMHtmHfQfA'\n",
        "\n",
        "# Download the file\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloaded_file = request.execute()\n",
        "\n",
        "with open('Gai_Dataset.zip', 'wb') as f:\n",
        "    f.write(downloaded_file)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile('Gai_Dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "# Clean up: Delete the downloaded zip file\n",
        "os.remove('Gai_Dataset.zip')\n",
        "\n",
        "print('Extraction completed successfully.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6qndM9q_tUB",
        "outputId": "13b45c5b-09b9-4706-db71-11137cf67038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#======================================================================================================================="
      ],
      "metadata": {
        "id": "XRW8Y_HU_tX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting HDF5 (.h5) to Tflite format"
      ],
      "metadata": {
        "id": "hrH6bwr4E7li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Path to the .h5 model\n",
        "h5_model_path = '/content/drive/MyDrive/GaiAppModelPath/GaiApp_Epoch10BestMobileNet.h5'\n",
        "\n",
        "# Load the Keras model\n",
        "keras_model = tf.keras.models.load_model(h5_model_path)\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TensorFlow Lite model\n",
        "tflite_model_path = 'GaiApp_Epoch10.tflite'\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Model converted and saved as:\", tflite_model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPWaZWp5_ta0",
        "outputId": "29b7997e-e467-40e5-fd3a-eaf25c974e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n",
            "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
            "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
            "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model converted and saved as: GaiApp_Epoch10.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IzJWZEQFC-EV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EVALUATION TRAINING,TESTING,VALIDATION"
      ],
      "metadata": {
        "id": "cfludZl3BQ5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Constants\n",
        "IMAGE_SIZE1 = 240  # Height of the Image\n",
        "IMAGE_SIZE2 = 320  # Width of the Image\n",
        "\n",
        "# Specify the directory paths for the data\n",
        "root_dir = \"Gai_Dataset/\"\n",
        "train_dir = f\"{root_dir}train/\"\n",
        "\n",
        "# Collect the class names\n",
        "class_names = sorted(os.listdir(train_dir))\n",
        "print(class_names)\n",
        "print(len(class_names))\n",
        "\n",
        "\n",
        "# Load the training dataset\n",
        "def load_dataset(root_path, class_names, trim=None):\n",
        "    X_data = []\n",
        "    y_data = []\n",
        "    for class_idx, class_name in enumerate(class_names):\n",
        "        class_path = os.path.join(root_path, class_name)\n",
        "        images = os.listdir(class_path)\n",
        "        if trim:\n",
        "            images = images[:trim]\n",
        "        for image_name in images:\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "            image = load_img(image_path, target_size=(IMAGE_SIZE1, IMAGE_SIZE2))\n",
        "            image = img_to_array(image)\n",
        "            X_data.append(image)\n",
        "            y_data.append(class_idx)\n",
        "    return np.array(X_data), np.array(y_data)\n",
        "\n",
        "# Load the TFLite model\n",
        "tflite_model_path = '/content/drive/MyDrive/GaiAppModelPath/GaiApp_Epoch10.tflite'\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Load the datasets\n",
        "X_train, y_train = load_dataset(root_path=train_dir, class_names=class_names, trim=700)\n",
        "X_val, y_val = load_dataset(root_path=f\"{root_dir}valid/\", class_names=class_names)\n",
        "X_test, y_test = load_dataset(root_path=f\"{root_dir}test/\", class_names=class_names)\n",
        "\n",
        "# Normalize pixel values\n",
        "X_train = X_train / 255.0\n",
        "X_val = X_val / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Evaluate the TFLite model on training dataset\n",
        "train_accuracy = 0\n",
        "num_train_samples = len(X_train)\n",
        "\n",
        "for i in range(num_train_samples):\n",
        "    input_data = X_train[i].reshape(1, IMAGE_SIZE1, IMAGE_SIZE2, 3).astype(np.float32)\n",
        "    expected_output = np.array([y_train[i]])\n",
        "\n",
        "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])\n",
        "\n",
        "    predicted_class = np.argmax(output)\n",
        "    if predicted_class == expected_output[0]:\n",
        "        train_accuracy += 1\n",
        "\n",
        "train_accuracy /= num_train_samples\n",
        "print(f\"Training accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate the TFLite model on validation dataset\n",
        "val_accuracy = 0\n",
        "num_val_samples = len(X_val)\n",
        "\n",
        "for i in range(num_val_samples):\n",
        "    input_data = X_val[i].reshape(1, IMAGE_SIZE1, IMAGE_SIZE2, 3).astype(np.float32)\n",
        "    expected_output = np.array([y_val[i]])\n",
        "\n",
        "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])\n",
        "\n",
        "    predicted_class = np.argmax(output)\n",
        "    if predicted_class == expected_output[0]:\n",
        "        val_accuracy += 1\n",
        "\n",
        "val_accuracy /= num_val_samples\n",
        "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate the TFLite model on testing dataset\n",
        "test_accuracy = 0\n",
        "num_test_samples = len(X_test)\n",
        "\n",
        "for i in range(num_test_samples):\n",
        "    input_data = X_test[i].reshape(1, IMAGE_SIZE1, IMAGE_SIZE2, 3).astype(np.float32)\n",
        "    expected_output = np.array([y_test[i]])\n",
        "\n",
        "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])\n",
        "\n",
        "    predicted_class = np.argmax(output)\n",
        "    if predicted_class == expected_output[0]:\n",
        "        test_accuracy += 1\n",
        "\n",
        "test_accuracy /= num_test_samples\n",
        "print(f\"Testing accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV-Vd7wU_tdq",
        "outputId": "b0899b6f-f8fa-46de-abec-96789a4f779c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Apple', 'Banana', 'Grape', 'Mango', 'Strawberry']\n",
            "5\n",
            "Training accuracy: 0.9917\n",
            "Validation accuracy: 0.8667\n",
            "Testing accuracy: 0.7900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#============================================================================================"
      ],
      "metadata": {
        "id": "PeKQvN_l_tgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-hGyCf2o_tkl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}